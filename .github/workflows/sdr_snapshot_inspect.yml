name: SDR Snapshot & Inspect

on:
  workflow_dispatch:
    inputs:
      env:
        description: Environment (dev|staging|prod)
        required: true
        default: dev
        type: choice
        options:
          - dev
          - staging
          - prod
      sample_lines:
        description: Number of sample lines to capture from each file
        required: false
        default: '200'

concurrency:
  group: sdr-inspect-${{ inputs.env }}
  cancel-in-progress: false

jobs:
  snapshot:
    name: Snapshot & Inspect
    runs-on: ubuntu-latest
    environment: ${{ inputs.env }}
    permissions:
      contents: read
    env:
      RAW_SDR_BUCKET: ${{ vars.RAW_SDR_BUCKET }}
      RAW_SDR_PREFIX: ${{ vars.RAW_SDR_PREFIX }}
      STORAGE_ACCESS_KEY_ID: ${{ secrets.STORAGE_ACCESS_KEY_ID }}
      STORAGE_SECRET_ACCESS_KEY: ${{ secrets.STORAGE_SECRET_ACCESS_KEY }}
      STORAGE_ENDPOINT: ${{ secrets.STORAGE_ENDPOINT }}
      SDR_ZIP_URL: ${{ secrets.SDR_ZIP_URL }}
      SAMPLE_LINES: ${{ inputs.sample_lines }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'

      - name: Install tools
        run: |
          python -m pip install --upgrade pip
          pip install awscli

      - name: Prepare directories
        run: |
          mkdir -p data/raw_data/SDRDownload
          mkdir -p data/raw_data/samples/heads

      - name: Check SDR URL connectivity (HEAD)
        run: |
          set -euo pipefail
          if [ -z "${SDR_ZIP_URL:-}" ]; then
            echo "SDR_ZIP_URL is not set" >&2
            exit 2
          fi
          HOST=$(echo "$SDR_ZIP_URL" | awk -F/ '{print $3}')
          echo "Resolving host: $HOST"
          getent hosts "$HOST" || true
          echo "Fetching HEAD (no body) with curl"
          curl -I -sS -L --connect-timeout 15 --max-time 60 -A "GitHubActions-curl/8" "$SDR_ZIP_URL" -o /dev/null -w "http=%{http_code} redirect=%{redirect_url}\n"

      - name: Download SDR ZIP
        run: |
          set -euo pipefail
          curl -fL --retry 5 --retry-delay 5 --retry-all-errors --connect-timeout 20 --max-time 1800 -A "GitHubActions-curl/8" "$SDR_ZIP_URL" -o data/raw_data/sdr.zip
          BYTES=$(stat -c%s data/raw_data/sdr.zip 2>/dev/null || stat -f%z data/raw_data/sdr.zip 2>/dev/null || echo 0)
          if [ "${BYTES:-0}" -le 0 ]; then
            echo "Downloaded file is empty; failing early" >&2
            exit 3
          fi

      - name: Unzip SDR ZIP
        run: |
          set -euo pipefail
          if command -v unzip >/dev/null 2>&1; then
            unzip -n data/raw_data/sdr.zip -d data/raw_data/
          else
            echo "unzip not found; installing zip/unzip"
            sudo apt-get update -y && sudo apt-get install -y --no-install-recommends unzip >/dev/null
            unzip -n data/raw_data/sdr.zip -d data/raw_data/
          fi

      - name: List extracted .txt files
        run: |
          set -euo pipefail
          echo "Top-level .txt under data/raw_data/SDRDownload:"
          ls -l data/raw_data/SDRDownload/*.txt 2>/dev/null || true
          echo "Recursive .txt under data/raw_data/SDRDownload (first 100):"
          find data/raw_data/SDRDownload -type f -name "*.txt" | head -100

      - name: Inspect and create manifest
        run: |
          python data/scripts/sdr_snapshot_inspect.py \
            --source-dir data/raw_data/SDRDownload \
            --samples-dir data/raw_data/samples/heads \
            --manifest data/raw_data/manifest.json \
            --sample-lines "$SAMPLE_LINES" \
            --zip-path data/raw_data/sdr.zip
          echo "Inspector exit code: $?" || true
          echo "Listing sample heads produced:" || true
          find data/raw_data/samples/heads -type f -name "*.head.txt" -maxdepth 1 -print || true

      - name: Upload to R2
        run: |
          set -euo pipefail
          export AWS_ACCESS_KEY_ID="$STORAGE_ACCESS_KEY_ID"
          export AWS_SECRET_ACCESS_KEY="$STORAGE_SECRET_ACCESS_KEY"
          export AWS_DEFAULT_REGION="auto"
          TIMESTAMP=$(date -u +%Y%m%dT%H%M%SZ)
          export SNAPSHOT_PREFIX="$RAW_SDR_PREFIX/snapshots/$TIMESTAMP"
          aws s3 cp data/raw_data/sdr.zip s3://$RAW_SDR_BUCKET/$SNAPSHOT_PREFIX/ --endpoint-url "$STORAGE_ENDPOINT"
          aws s3 cp data/raw_data/manifest.json s3://$RAW_SDR_BUCKET/$SNAPSHOT_PREFIX/ --endpoint-url "$STORAGE_ENDPOINT"
          aws s3 cp data/raw_data/samples/heads s3://$RAW_SDR_BUCKET/$SNAPSHOT_PREFIX/samples/heads/ --recursive --exclude "*" --include "*.head.txt" --endpoint-url "$STORAGE_ENDPOINT"
          echo "SNAPSHOT_PREFIX=$SNAPSHOT_PREFIX" >> $GITHUB_ENV

      - name: Upload CI artifacts
        uses: actions/upload-artifact@v4
        with:
          name: sdr-inspect-${{ inputs.env }}
          path: |
            data/raw_data/manifest.json
            data/raw_data/samples/heads/**

      - name: Job summary
        run: |
          python - << 'PY'
          import json, os
          manifest=json.load(open('data/raw_data/manifest.json'))
          lines=[]
          lines.append(f"### SDR Snapshot: {manifest.get('fetched_at','')}")
          lines.append("")
          lines.append("| File | Size (bytes) | Lines | Columns |")
          lines.append("|---|---:|---:|---|")
          for f in manifest.get('files', []):
            cols=",".join(f.get('header_fields', []))
            cols=cols.replace('|','\\|')
            lines.append(f"| {f.get('name','')} | {f.get('size_bytes',0)} | {f.get('line_count',0)} | {cols} |")
          with open(os.environ['GITHUB_STEP_SUMMARY'],'a',encoding='utf-8') as fh:
            fh.write("\n".join(lines)+"\n")
          PY


