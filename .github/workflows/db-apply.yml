name: Apply DB Init (DS2)

on:
  workflow_dispatch:
    inputs:
      env:
        description: Which environment's secrets to use (dev|staging|prod)
        required: false
        default: prod
        type: choice
        options:
          - dev
          - staging
          - prod

permissions:
  contents: read

concurrency:
  group: db-apply-${{ inputs.env }}
  cancel-in-progress: false

jobs:
  apply:
    name: Apply SQL init files (${{ inputs.env }})
    runs-on: ubuntu-latest
    environment: ${{ (inputs.env != '' && inputs.env) || 'prod' }}
    env:
      DATABASE_URL: ${{ secrets.DATABASE_URL }}
      RAW_SDR_BUCKET: ${{ vars.RAW_SDR_BUCKET }}
      RAW_SDR_PREFIX: ${{ vars.RAW_SDR_PREFIX }}
      STORAGE_ACCESS_KEY_ID: ${{ secrets.STORAGE_ACCESS_KEY_ID }}
      STORAGE_SECRET_ACCESS_KEY: ${{ secrets.STORAGE_SECRET_ACCESS_KEY }}
      STORAGE_ENDPOINT: ${{ secrets.STORAGE_ENDPOINT }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Install psql client
        run: |
          sudo apt-get update -y
          sudo apt-get install -y --no-install-recommends postgresql-client

      - name: Check DB connectivity
        run: |
          if [ -z "${DATABASE_URL:-}" ]; then echo "DATABASE_URL is not set" >&2; exit 2; fi
          psql "$DATABASE_URL" -v ON_ERROR_STOP=1 -c "select version();"

      - name: Install AWS CLI
        run: |
          sudo apt-get update -y
          sudo apt-get install -y --no-install-recommends python3-pip
          python3 -m pip install --upgrade pip
          python3 -m pip install --user awscli
          echo "$HOME/.local/bin" >> "$GITHUB_PATH"

      - name: Fetch latest raw SDR schema from R2 (if available)
        run: |
          set -euo pipefail
          mkdir -p data/tmp
          if [ -z "${RAW_SDR_BUCKET:-}" ] || [ -z "${RAW_SDR_PREFIX:-}" ]; then
            echo "RAW_SDR_BUCKET/RAW_SDR_PREFIX not set; skipping raw schema fetch"
            exit 0
          fi
          export AWS_ACCESS_KEY_ID="$STORAGE_ACCESS_KEY_ID"
          export AWS_SECRET_ACCESS_KEY="$STORAGE_SECRET_ACCESS_KEY"
          export AWS_DEFAULT_REGION="auto"
          SNAPSHOTS_PREFIX="$RAW_SDR_PREFIX/snapshots/"
          echo "Listing snapshots under s3://$RAW_SDR_BUCKET/$SNAPSHOTS_PREFIX"
          LATEST=$(aws s3 ls "s3://$RAW_SDR_BUCKET/$SNAPSHOTS_PREFIX" --endpoint-url "$STORAGE_ENDPOINT" | awk '{print $NF}' | sed 's#/##' | sort | tail -n 1 || true)
          if [ -z "${LATEST:-}" ]; then
            echo "No snapshots found; skipping raw schema fetch"
            exit 0
          fi
          SRC_SCHEMA="s3://$RAW_SDR_BUCKET/$SNAPSHOTS_PREFIX$LATEST/sdr_raw_schema.sql"
          SRC_ALIAS="s3://$RAW_SDR_BUCKET/$SNAPSHOTS_PREFIX$LATEST/sdr_header_aliases.json"
          echo "Fetching $SRC_SCHEMA and $SRC_ALIAS"
          aws s3 cp "$SRC_SCHEMA" data/tmp/sdr_raw_schema.sql --endpoint-url "$STORAGE_ENDPOINT" || true
          aws s3 cp "$SRC_ALIAS" data/tmp/sdr_header_aliases.json --endpoint-url "$STORAGE_ENDPOINT" || true
          if [ -s data/tmp/sdr_raw_schema.sql ]; then
            echo "Raw schema downloaded: data/tmp/sdr_raw_schema.sql"
          else
            echo "Raw schema not present in latest snapshot; continuing"
          fi

      - name: Apply 01_postgis.sql
        run: psql "$DATABASE_URL" -v ON_ERROR_STOP=1 -f db/init/01_postgis.sql

      - name: Apply 03_well_reports_fix.sql
        run: psql "$DATABASE_URL" -v ON_ERROR_STOP=1 -f db/init/03_well_reports_fix.sql

      - name: Apply raw SDR schema (if downloaded)
        run: |
          if [ -s data/tmp/sdr_raw_schema.sql ]; then psql "$DATABASE_URL" -v ON_ERROR_STOP=1 -f data/tmp/sdr_raw_schema.sql; else echo "No raw schema file to apply"; fi

      - name: Download latest snapshot ZIP (for ETL)
        run: |
          set -euo pipefail
          if [ -z "${RAW_SDR_BUCKET:-}" ] || [ -z "${RAW_SDR_PREFIX:-}" ]; then
            echo "RAW_SDR_BUCKET/RAW_SDR_PREFIX not set; skipping snapshot ZIP fetch"; exit 0; fi
          export AWS_ACCESS_KEY_ID="$STORAGE_ACCESS_KEY_ID"
          export AWS_SECRET_ACCESS_KEY="$STORAGE_SECRET_ACCESS_KEY"
          export AWS_DEFAULT_REGION="auto"
          SNAPSHOTS_PREFIX="$RAW_SDR_PREFIX/snapshots/"
          LATEST=$(aws s3 ls "s3://$RAW_SDR_BUCKET/$SNAPSHOTS_PREFIX" --endpoint-url "$STORAGE_ENDPOINT" | awk '{print $NF}' | sed 's#/##' | sort | tail -n 1 || true)
          if [ -z "${LATEST:-}" ]; then echo "No snapshots found"; exit 0; fi
          mkdir -p data/raw_data
          aws s3 cp "s3://$RAW_SDR_BUCKET/$SNAPSHOTS_PREFIX$LATEST/sdr.zip" data/raw_data/sdr.zip --endpoint-url "$STORAGE_ENDPOINT"
          if command -v unzip >/dev/null 2>&1; then unzip -n data/raw_data/sdr.zip -d data/raw_data/; else sudo apt-get update -y && sudo apt-get install -y --no-install-recommends unzip >/dev/null && unzip -n data/raw_data/sdr.zip -d data/raw_data/; fi

      - name: Apply 03_sdr_children.sql (DS2)
        run: psql "$DATABASE_URL" -v ON_ERROR_STOP=1 -f db/init/03_sdr_children.sql

      - name: Apply 04_indexes.sql (optional)
        run: |
          if [ -f db/init/04_indexes.sql ]; then psql "$DATABASE_URL" -v ON_ERROR_STOP=1 -f db/init/04_indexes.sql; fi

      - name: Apply 04_alerts.sql (optional)
        run: |
          if [ -f db/init/04_alerts.sql ]; then psql "$DATABASE_URL" -v ON_ERROR_STOP=1 -f db/init/04_alerts.sql; fi

      - name: Run DS4 ETL (sample; WellData/WellCompletion/WellBoreHole/Casing/Filter)
        env:
          ALIASES_PATH: data/tmp/sdr_header_aliases.json
          SOURCE_DIR: data/raw_data/SDRDownload
        run: |
          # For safety, only run if alias file and source dir are present (from latest snapshot)
          if [ -f "$ALIASES_PATH" ] && [ -d "$SOURCE_DIR" ]; then \
            python3 data/scripts/sdr_etl_load.py --source-dir "$SOURCE_DIR" --aliases "$ALIASES_PATH" --database-url "$DATABASE_URL" --batch-size 1000; \
          else \
            echo "DS4 ETL skipped (missing source/aliases)"; \
          fi

      - name: Job summary
        run: |
          echo "### DB Init Applied" >> "$GITHUB_STEP_SUMMARY"
          echo "" >> "$GITHUB_STEP_SUMMARY"
          echo "Environment: ${{ (inputs.env != '' && inputs.env) || 'prod' }}" >> "$GITHUB_STEP_SUMMARY"
          echo "" >> "$GITHUB_STEP_SUMMARY"
          echo "Files:" >> "$GITHUB_STEP_SUMMARY"
          echo "- db/init/01_postgis.sql" >> "$GITHUB_STEP_SUMMARY"
          echo "- db/init/03_well_reports_fix.sql" >> "$GITHUB_STEP_SUMMARY"
          if [ -s data/tmp/sdr_raw_schema.sql ]; then echo "- (from snapshot) data/tmp/sdr_raw_schema.sql" >> "$GITHUB_STEP_SUMMARY"; fi
          echo "- db/init/03_sdr_children.sql" >> "$GITHUB_STEP_SUMMARY"
          if [ -f db/init/04_indexes.sql ]; then echo "- db/init/04_indexes.sql" >> "$GITHUB_STEP_SUMMARY"; fi
          if [ -f db/init/04_alerts.sql ]; then echo "- db/init/04_alerts.sql" >> "$GITHUB_STEP_SUMMARY"; fi

  verify:
    name: Verify schema (${{ (inputs.env != '' && inputs.env) || 'prod' }})
    runs-on: ubuntu-latest
    needs: apply
    environment: ${{ (inputs.env != '' && inputs.env) || 'prod' }}
    env:
      DATABASE_URL: ${{ secrets.DATABASE_URL }}
    steps:
      - name: Install psql client
        run: |
          sudo apt-get update -y
          sudo apt-get install -y --no-install-recommends postgresql-client

      - name: Check DB connectivity
        run: |
          if [ -z "${DATABASE_URL:-}" ]; then echo "DATABASE_URL is not set" >&2; exit 2; fi
          psql "$DATABASE_URL" -v ON_ERROR_STOP=1 -c "select version();"

      - name: Verify extensions
        run: |
          echo "### Extensions" >> "$GITHUB_STEP_SUMMARY"
          psql "$DATABASE_URL" -t -A -v ON_ERROR_STOP=1 -c "SELECT extname FROM pg_extension WHERE extname IN ('postgis','pg_trgm') ORDER BY 1;" | sed 's/^/- /' >> "$GITHUB_STEP_SUMMARY"

      - name: Verify DS2 child tables exist
        run: |
          echo "\n### DS2 child tables present" >> "$GITHUB_STEP_SUMMARY"
          psql "$DATABASE_URL" -t -A -v ON_ERROR_STOP=1 -c "SELECT table_name FROM information_schema.tables WHERE table_schema='public' AND table_name IN ('well_boreholes','well_casings','well_filters','well_seal_ranges','well_packers','well_plug_back','well_strata','well_levels','well_test','well_injurious_constituent','well_lithology','plug_reports','plug_boreholes','plug_casing','plug_range') ORDER BY 1;" | sed 's/^/- /' >> "$GITHUB_STEP_SUMMARY"

      - name: Verify FKs to well_reports
        run: |
          echo "\n### Foreign keys to well_reports" >> "$GITHUB_STEP_SUMMARY"
          psql "$DATABASE_URL" -t -A -v ON_ERROR_STOP=1 -c "SELECT conrelid::regclass || ' -> ' || confrelid::regclass FROM pg_constraint WHERE contype='f' AND confrelid='well_reports'::regclass ORDER BY 1;" | sed 's/^/- /' >> "$GITHUB_STEP_SUMMARY"

      - name: Verify sdr_id indexes exist
        run: |
          echo "\n### sdr_id indexes on child tables" >> "$GITHUB_STEP_SUMMARY"
          psql "$DATABASE_URL" -t -A -v ON_ERROR_STOP=1 -c "SELECT tablename || ':' || indexname FROM pg_indexes WHERE schemaname='public' AND tablename IN ('well_boreholes','well_casings','well_filters','well_seal_ranges','well_packers','well_plug_back','well_strata','well_levels','well_test','well_injurious_constituent','well_lithology','plug_boreholes','plug_casing','plug_range') AND indexdef ILIKE '%(sdr_id)%' ORDER BY 1;" | sed 's/^/- /' >> "$GITHUB_STEP_SUMMARY"

      - name: Verify raw schema (if applied)
        run: |
          echo "\n### Raw schema tables (sdr_raw) [first 20]" >> "$GITHUB_STEP_SUMMARY"
          psql "$DATABASE_URL" -t -A -v ON_ERROR_STOP=1 -c "SELECT table_name FROM information_schema.tables WHERE table_schema='sdr_raw' ORDER BY 1 LIMIT 20;" | sed 's/^/- /' >> "$GITHUB_STEP_SUMMARY" || true
